REF 컨테이너 인프라 구축을 위한 쿠버네티스 / 도커  
REF 쿠버네티스 차근차근 다지기

# 1. 컨테이너 인프라 환경

컨테이너를 중심으로 구성된 인프라 환경. 컨테이너란 하나의 운영체제 커널에서 독립적으로 실행되는 프로세스이다. 가상화 상태에서 동작하는 것 보다 가볍고 빠르다.
<br>
<br>
인프라를 구현하는 설계 방식은 크게 두가지이다. 

### 1. 모놀리식 아키텍처

하나의 어플리케이션에 여러 기능이 통합돼 있는 구조. 초기 단계에 설계하기 좋고 코드 관리가 단순해진다. 어느 곳에서 수정한 사항이 다른 서비스에 영향을 미칠 수 있고 서비스가 성장 할 수록 단순했던 서비스 간의 관계가 복잡해진다. 

### 2. 마이크로 서비스 아키텍처

하나의 서비스를 독립적으로 개발하여 기능별로 구성되어 있는 구조다. 독립적으로 실행되기 때문에 어떤 변경사항이 다른 서비스에 영향을 미치지 않고, 특정 서비스만 확장 가능하고 개발된 서비스를 재사용할 수 있는 장점이 있다. 하지만 모놀리식에 비해 복잡도가 높으며 각 서비스가 유기적으로 통신하는 구조이기 때문에 네트워크 호출 횟수가 성능에 영향을 줄 수 있다.  

![](https://user-images.githubusercontent.com/71869837/128013245-15018ca6-121e-495a-a82d-4b7a87bf024c.PNG)


컨터이너를 서비스 단위로 포장해 손쉽게 배포하고 확장할 수 있기 때문에 마이크로 서비스 아키텍처를 이용해 컨테이너 인프라 환경을 구축하는 것이 유리하다.

VM 과 달리 컨테이너는 전체 OS가 아닌 필요한 라이브러리와 설정만 포함한다. 그렇게 만들어진 많은 컨터네이너들이 단일 Linux 호스트 위에서 Linux kernel 을 공유해서 사용하기 때문에 더 효율적으로 작동한다.  
<br>
# 2. 쿠버네티스
원하는 라이브러리, 설정으로 이루어진 컨테이너들을 관리해주는 것이 Container Orchestration 이고 대표적으로 쿠버네티스가 있다. 특징으로는

* **Automatic binpacking**  
클러스터 안에 여러 worker 노드가 존재하는데 컨테이너를 올릴 때 어느 worker 노드에 올릴 것인지 가용성에 대한 희생 없이, 리소스 사용과 제약 사항을 기준으로 자동으로 컨테이너를 스케쥴해준다.

* **Self Healing**  
노드에 컨테이너가 죽었다면 살려주고 해당 노드가 죽었다면 다른 노드에 같은 컨테이너를 대체해준다.

* **Horizontal scaling**  
리소스 사용에 따라 자동으로 애플리케이션을 확장

* **Service discovery and Load balancing**  
수 많은 노드에서 어디에 서비스가 존재하는지 찾을 수 있고, 여러 개의 container 를 묶어 단일 service 로 부여하면 단일 DNS name 으로 접근하도록 로드 밸런싱을 제공한다.

* **Automatic rollouts and rollbacks**  
다운타임 없이 애플리케이션의 새로운 버전 및 설정에 대한 롤아웃/롤백을 자동으로 해준다.

쿠버네티스를 구성하기 위해 클러스터를 구축해야한다. 클러스터를 이루는 구성요소는 마스터 컴포넌트와 노드 컴포넌트로 구분된다. 

### 1. 마스터 컴포넌트
* **kubectl**  
쿠버네티스 클러스터에 명령을 내리는 역할을 한다. API 서버와 주로 통신하며 작업을 수행한다.

* **API 서버**  
쿠버네티스 클러스터의 중심 역할을 하는 통로이다. 요청을 분석하고 실행을 위해 여러 요소들과 통신한다. 회사에서 관리자라고 생각하면된다.

* **etcd**  
구성 요소들의 상태 값이 모두 저장되는 곳이다. 회사의 관리자가 모든 보고 내용을 기록하는 노트라고 생각하면 쉽다. 실제로 다른 요소는 상태 값을 저장하지 않는다. 때문에 etcd 의 정보를 가지고 있다면 쿠버네티스 클러스터는 복귀할 수 있다. 

* **컨트롤러 매니저**  
쿠버네티스 클러스터의 오브젝트 상태를 관리한다.
    * 노드 컨트롤러 : 여러 노드의 상태 체그와 복구를 담당한다.
    * 레플리카셋 컨트롤러 : 레플리카셋에 요청받은 파드 개수대로 파드를 생성한다. 
    * 앤드포인트 컨트롤러 : 서비스와 파드를 연결하는 연할을 한다.

* **스케줄러**  
노드의 상태와 자원, 레이블, 요구 조건 등을 고려해 파드를 어떤 노드에 생성할 것인지 결정하고 할당한다. 

### 2. 노드 컴포넌트

* **kubelet**  
파드의 구성 내용(PodSpec)을 받아서 컨테이너 런타임으로 전달하고, 파드 안의 컨테이너들이 정상적으로 작동하는지 모니터링한다.

* **컨테이너 런타임**  
파드를 이루는 컨테이너의 실행을 담당한다. 파드 안에 다양한 종류의 컨테이너가 문제 없이 작동하게 만드는 표준 인터페이스이다. 

* **kube-proxy**  
쿠버네티스 클러스터는 파드가 위치한 노드에 kube-proxy를 통해 파드가 통신할 수 있는 네트워크를 설정한다.

쿠버네티스 클러스터를 구성하는 모든 요소는 파드(Pod)로 구성되어 있다. 파드란 한 개 이상의 컨테이너로 단일 목적의 일을 하기 위해 모인 쿠버네티스 단위이다. 이 파드의 생명주기(생성, 수정, 삭제) 를 통해 쿠버네티스의 구성 요소가 어떻게 동작하는지 알아보자. 

![](https://user-images.githubusercontent.com/71869837/128154407-73561579-3769-470c-b97a-7c22dcf39d11.jpg)

우선 마스터 컴포넌트를 구성하는 요소를 가상머신 하나에 몰아 넣고 마스터 노드로 만들어주고 실제 어플리케이션을 배포하는 일을 하는 가상머신을 워커 노드로 만들었다.  

1. 관리자가 kubectl 로 Pod 생성 요청을 하면 APi 서버에 요청이 들어온다.
2. API 서버에 전달된 내용이 있으면 이를 etcd 에 모두 기록해 클러스터의 상태 값을 최신화한다. 따라서 업데이트할 때마다 모두 API 서버를 통해 etcd 에 기록된다.
3. API 서버에 파드 생성 요청을 컨트롤러 매니저가 인지하고 파드를 생성하고 이 상태를 API 서버에 전달한다.
4. API 서버에 파드가 생성된 것을 스케줄러가 인지하고 해당 파드를 어떤 워크 노드에 적용할지 조건을 고려해 결정하고 해당 워커 노드에 파드를 띄우도록 요청한다. 
5. 스케줄러가 kubelet 으로 지정한 워커 노드에 파드가 속해 있는지 확인한다.
6. kubelet 에서 컨테이너 런타임으로 파드 생성을 요청한다.
7. 파드가 생성된다.
8. 파드가 사용 가능한 상태가 된다. 
